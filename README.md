‚≠ê PyTorch Fundamentals 

Hands-on implementation of the complete PyTorch training workflow.

üìå Overview

This repository contains practical project while learning PyTorch.

The notebook is implemented on Google Colab for smooth GPU support and easy experimentation.

ALL About PART 1:

üöÄ What‚Äôs Inside 
1. Data Preparation

Creating synthetic data

Converting data into PyTorch tensors

Splitting into training & testing sets

2. Model Pipeline

Defining a simple model using nn.Module

Choosing loss function and optimizer

Building the training loop

Implementing a testing/validation loop

Plotting loss curves and understanding model performance

3. Model Persistence

Saving the trained model

Loading the saved model

Verifying loaded model performs the same as before saving

üìä Results

Observed steady decline in loss, showing successful learning

Successfully tested the model on unseen data

Verified model reusability after saving/loading


All about part 2
In part 2 worked on classification problems.
where as follows was done:

0. Architecture of a classification neural network was learned.
1. Got binary classification data ready
2.  Build a PyTorch classification model
3.  Fit the model to data (training)
4.  Made predictions and evaluated a model (inference)
5.  Improved a model (from a model perspective)
6.  Non-linearity
7.  Replicated non-linear function
8.  Performed all together with multi-class classification.

Observation:
Until non-linearity was introduced model had a decision boundary as a straight line given dataset was circular,also increasing the hidden units & hidden layer & number of epochs did not much improved accuracy of model, later with introduction of non-linearity in model data was accurately classified.

   
üõ†Ô∏è Tech Used

Python

PyTorch

Google Colab

Matplotlib / NumPy

ü§ù Contributions

Suggestions and improvements are welcome!
Feel free to open an issue or submit a pull request.

‚≠ê If you find this helpful

Give the repo a star to support my learning journey!
